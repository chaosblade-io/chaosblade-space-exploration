下面是一份**可直接交给大模型落地实现**的“任务编排+数据入库”完整规格说明（已将你给出的信息统一、补全并细化到可执行级别）。内容包含：接口契约、状态机、逐阶段流程、数据读写与SQL、容错/幂等、伪代码骨架、样例请求/响应。你可以把这份文档当作实现说明书交给模型/工程同学。

---

## 1. 目标与产出

**目标**：新增一个接口，入参 `taskId`，完成一整套“生成→分析→录制→单故障串行执行→下发拦截规则→全量无故障压测→入库”的自动化编排。

**关键产出**：

* 一个新接口：`POST /api/tasks/{taskId}/execute`（返回 `executionId` 与实时状态）。
* 全流程执行状态记录在 `task_execution`。
* 生成的用例与 **baggage** 写入 `baggage_map`。
* 单故障串行回放结果写入 `intercept_replay_results`。
* 无故障全量压测指标写入 `test_result`。
* 通过 **Proxy** 完成请求模式分析/回放，完成拦截器下发与状态校验。

---

## 2. 名词与外部依赖

* **taskId**：业务检测任务ID（表：`detection_task`）。
* **executionId**：一次完整执行实例ID（表：`task_execution.id`）。
* **Proxy**：请求模式服务与回放服务，以及拦截器服务（你给定的 `/api/request-patterns/*` 与 `/api/interceptors/*` 等）。
* **Topologies**：`topology` 表（或接口）提供 `serviceList`。
* **Fault Config**：`fault_config` 表（或接口），本次任务生效的故障，包含 `type`。
* **Request Patterns**：`request_patterns` 表，以 `record_id`（分析批次）聚合每服务已观测到的 `method+url` 等。

---

## 4. 新接口契约

### 4.1 Endpoint

```
POST /api/tasks/{taskId}/execute
```

### 4.2 Request（可选体）

```json
{
  "force": false,                  // 可选。true 表示即使存在RUNNING的execution也新开，默认false
  "ttlSecForInterceptors": 600,    // 可选。拦截器TTL，默认600
  "waitAnalyzeTimeoutSec": 600,    // 可选。分析最大等待，默认600
  "waitInterceptorReadySec": 30    // 可选。拦截器就绪等待，默认30
}
```

> **说明**：接口最小化依赖，仅需 `taskId` 路径参数。请求体均为可选覆盖项。

### 4.3 Success Response

* **202 Accepted**（建议）：异步编排立即返回

```json
{
  "executionId": 123456,
  "status": "INIT",
  "message": "Execution accepted"
}
```


### 4.4 Error Response（统一错误格式，保持与你的规范一致）

```json
{
  "timestamp": "2025-09-04T18:42:15+08:00",
  "status": 400,
  "error": "Bad Request",
  "code": "VALIDATION_ERROR",
  "message": "必须提供namespace",
  "traceId": "c5a8f3e2e3a948e2"
}
```

**可能状态码**：
`400` 参数/校验失败；`404` 资源不存在；`409` 冲突（已有进行中的执行且 force=false）；`500` 服务器内部错误/下游异常。

---

## 4. 执行状态机（`task_execution.status`）

枚举值（你已定义，下面补充切换规则）：

* `INIT` → 新建执行记录
* `GENERATING_CASES` → 生成用例与 `baggage_map`
* `ANALYZING_PATTERNS` → 调用 Proxy 分析并轮询直到完成
* `RECORDING_READY` → 启动所有服务的请求/响应记录器
* `INJECTING_AND_REPLAYING` → 按“单故障串行”执行：注入 → 回放 → 入库
* `RULES_READY` → 由第4步产物生成并下发拦截规则；校验拦截器就绪
* `LOAD_TEST_BASELINE` → 执行全量无故障测试（并发= `detection_task.request_num`）并入库
* `DONE` → 全流程结束
* `FAILED` → 任意步骤错误，写入 `error_code/error_msg`

> 所有状态变迁写入 `task_execution.updated_at`，最终写 `finished_at`。

---

## 5. 数据表（已与你现有DDL对齐）

> 如无特别说明，均按你当前DDL执行。仅对**一个潜在不一致**给出可选修正（见 §9.3）。

### 5.1 `task_execution`（最终版）

```sql
DROP TABLE IF EXISTS `task_execution`;
CREATE TABLE `task_execution` (
  `id`                BIGINT UNSIGNED NOT NULL AUTO_INCREMENT COMMENT 'execution_id',
  `task_id`           BIGINT          NOT NULL COMMENT '业务任务ID',
  `namespace`         VARCHAR(128)    NOT NULL COMMENT '如 train-ticket',
  `req_def_id`        BIGINT          NULL     COMMENT '请求定义ID',
  `request_num`       INT             NOT NULL DEFAULT 1 COMMENT '入口并发',
  `status`            VARCHAR(32)     NOT NULL DEFAULT 'INIT' COMMENT 'INIT/GENERATING_CASES/ANALYZING_PATTERNS/RECORDING_READY/INJECTING_AND_REPLAYING/RULES_READY/LOAD_TEST_BASELINE/DONE/FAILED',
  `analyze_task_id`   VARCHAR(64)     NULL     COMMENT 'proxy 分析任务ID（task_...）',
  `record_id`         BIGINT          NULL     COMMENT '请求模式分析批次ID（用于回看）',
  `intercept_record_id` VARCHAR(64)   NULL     COMMENT '拦截器下发记录ID（如 exec_...）',
  `started_at`        DATETIME        NOT NULL DEFAULT CURRENT_TIMESTAMP,
  `finished_at`       DATETIME        NULL,
  `error_code`        VARCHAR(64)     NULL,
  `error_msg`         TEXT            NULL,
  `created_at`        DATETIME        NOT NULL DEFAULT CURRENT_TIMESTAMP,
  `updated_at`        DATETIME        NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  PRIMARY KEY (`id`),
  KEY `idx_task` (`task_id`),
  KEY `idx_status` (`status`),
  KEY `idx_record` (`record_id`),
  KEY `idx_intercept_record` (`intercept_record_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
```

### 5.2 `request_patterns`（沿用你现有表）

> 用于挑选每服务“代表性路由”（**method+url**）。

### 5.3 `baggage_map`（已改为 execution 维度，且服务内唯一）

```sql
CREATE TABLE `baggage_map` (
  `id` bigint unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',
  `execution_id` bigint NOT NULL COMMENT 'task_execution.id',
  `service_name` varchar(200) COLLATE utf8mb4_unicode_ci NOT NULL COMMENT '服务名，如 ts-order-service',
  `value` varchar(1024) COLLATE utf8mb4_unicode_ci NOT NULL COMMENT 'baggage 串，如 chaos.f1=...,chaos.f2=...',
  `created_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_exec_service` (`execution_id`,`service_name`),
  KEY `idx_service` (`service_name`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
```

### 5.4 `intercept_replay_results`（沿用你当前定义）

> **建议**把 `execution_id` 类型与 `task_execution.id` 对齐为 `BIGINT`（见 §9.3）。如果暂不改，也能工作。

### 5.5 `test_result`（沿用你当前定义）

---

## 6. 阶段性流程（权威执行顺序）

### 6.1 阶段 1：生成测试用例（`generateSimplifiedForTask`）

**输入**：`taskId`
**依赖**：

* `detection_task`：取 `reqDefId`、`request_num`、`namespace`。
* `topology`：取 `serviceList`（参与分析与回放的服务）。
* `fault_config`：当前任务生效的 `(service, faultType)` 集合（同一服务可能多个故障）。
* `request_patterns`：已存在时用于挑“代表性路由”。

**规则**：

* **Baseline**：1条，无故障，用于对比。
* **单故障用例**：对每个配置了故障的 `(service, faultType)` 生成1条；若同一服务有多个故障，**同一服务内部串行**（A完成→B）。
* **目标URL/方法**（按服务选1条）：

  1. **优先**用 `request_patterns[serviceName]` 中出现频次最高（或业务关键）的 `method+url`；
  2. 若无历史，回退到 `reqDefId` 的请求模板（method+path 需可推导）。
* **baggage 生成**：对每个 `(service, faultType)` 生成一个 token：
  `chaos.f{n} = {serviceName}-{faultType}`

  * 单个用例执行时只带**一个** token（该用例的故障），命名一律放到 `chaos.f1`（避免混淆）。
  * `baggage_map` 层面，为同一 `service` 聚合**该服务所有故障**的 tokens，按故障列表顺序生成逗号分隔串（例如：`chaos.f1=ts-order-service-pod-delay,chaos.f2=ts-order-service-container-delay`），用于规则生成与可观测。

**写库**：

* 新建 `executionId`（插入 `task_execution`，`status='GENERATING_CASES'`）。
* 以 `executionId` 为维度写 `baggage_map`：每服务1行，`value` 为该服务**所有故障**拼接串。
* 内部内存（或缓存）形成用例清单：

  ```ts
  interface TestCase {
    caseId: string;                      // 内部ID
    type: 'BASELINE' | 'SINGLE_FAULT';
    serviceName?: string;                // 单故障用
    faultType?: string;                  // 单故障用
    request: { method: string; url: string; headers: object; body?: any };
    concurrency: number;                 // BASELINE=1；单故障=1
  }
  ```

> 状态迁移：`GENERATING_CASES` → `ANALYZING_PATTERNS`

---

### 6.2 阶段 2：触发“请求模式分析”（Proxy）

* `POST /api/request-patterns/analyze`
  **请求体**：使用 `reqDefId/namespace/serviceList/record_id` 等（与你给出的示例保持一致）。
  **成功回执**：保存 `analyze_task_id`（如 `task_175...`）与 `record_id` 到 `task_execution`。

* 轮询：
  `GET /api/request-patterns/tasks/{analyze_task_id}` 直到 `status == COMPLETED`（或失败/超时）。
  **超时**：`waitAnalyzeTimeoutSec`，超时标记 `FAILED`（`error_code=ANALYZE_TIMEOUT`）。

> 状态迁移：`ANALYZING_PATTERNS` → `RECORDING_READY`

---

### 6.4 阶段 4：按“单故障串行”执行所有用例（注入 → proxy 回放 → 入库）

**执行顺序**：

* 按服务分组，服务内按 `fault_config` 的稳定顺序 **串行**。
* 对于每个 `(serviceName, faultType)`：

  1. **注入**：调用你的故障注入器（此处为外部组件，假设存在 `injectFault(serviceName, faultType)` 与 `revokeFault(...)`；若用 baggage 触发拦截，则此步可为**设置拦截条件**而非真实注入）。
  2. **回放**：

     * 调用：`GET /api/request-patterns/replay/{namespace}/{serviceName}`
     * 请求头带：`baggage: chaos.f1={serviceName}-{faultType}`（**仅1个** token）
     * 请求体（你示例里的）：

       ```json
       {
         "detection_task_id": <taskId>,
         "namespace": "<ns>",
         "service_name": "<serviceName>"
       }
       ```
     * 解析响应里的 `url/method/statusCode/responseHeaders/responseBody`，将**本次回放请求时所用的 headers**（含 `baggage`）一并入库。
  3. **入库**：写入 `intercept_replay_results`：

     * `task_id` = `taskId`
     * `execution_id` = `executionId`
     * `service_name` = `<serviceName>`
     * `fault_type` = `<faultType>`
     * `request_url/request_method/request_headers/request_body`
     * `response_status/response_headers/response_body`
  4. **撤销**（若做了真实注入/配置变更，需要清理；如仅靠 `baggage` 触发，不一定需撤销）。
* 若任一故障执行失败：

  * 记录 `FAILED`（`error_code=REPLAY_FAILED`、`error_msg` 带服务与故障信息），并**继续下一个服务**（**可选策略**：也可立即停止，本方案推荐“继续”，以最大化获取数据）。

> 执行完成：状态迁移到 `RULES_READY`。

---

### 6.5 阶段 5：由阶段4产物生成/下发拦截规则（带 baggage）

**生成规则项**（按服务聚合）：

* 数据来源：

  * `baggage_map(execution_id, service_name).value`（该服务所有故障的 `chaos.f{n}` 列表）。
  * `intercept_replay_results` 最近一轮（本 `execution_id`）的 `method+path` 与 `response` 作为拦截模板。

* 构造 `/api/interceptors/upsert` 请求体：

  ```json
  {
    "namespace": "<namespace>",
    "recordId": "exec_<executionId>",
    "ttlSec": <ttlSecForInterceptors>,
    "items": [
      {
        "serviceName": "<service>",
        "method": "<POST|GET|...>",
        "path": "<从request_url解析出path>",
        "baggageTokens": [
          "chaos.f1=<service>-<faultA>",
          "chaos.f2=<service>-<faultB>"
        ],
        "respStatus": <来自回放或自定义>,
        "respHeaders": {"content-type": "application/json;charset=UTF-8"},
        "respBody": "<回放的response_body 或 你示例里的固定JSON>"
      }
      // 每个服务可下发多个path项；最小可只对关键path下发一条
    ]
  }
  ```

  > **匹配逻辑**：任意 `baggageTokens` 命中即拦截（“或”逻辑），与你的注释一致。

* 成功响应如你示例：保存 `intercept_record_id = "exec_<executionId>"` 到 `task_execution`。

* **就绪校验**（可选）：`GET /api/fixtures/record/{recordId}/status`，在 `waitInterceptorReadySec` 内轮询 `exists=true`，否则 `FAILED`（`error_code=INTERCEPTOR_NOT_READY`）。

> 状态迁移：`RULES_READY` → `LOAD_TEST_BASELINE`

---

### 6.6 阶段 6：执行全量无故障测试（并发由 `detection_task.request_num` 控制）→ 入库

* **无故障**：不带任何 `baggage` 注入；确保未持久化的注入已撤销；拦截器存在但不会匹配（无 `baggage`）。
* **并发**：使用 `detection_task.request_num`。
* **目标流量**：

  * 推荐使用在阶段2完成后得到的 `request_patterns` 中 **每服务1-3条代表性路由** 组成“全量集合”；
  * 或者按你的业务定义的“完整业务流”模板（`reqDefId`）。
* **统计入库**（表 `test_result`）：

  * 维度：`execution_id + test_case_id`（对每个被压测的路由/场景生成一个 `test_case_id`）。
  * 指标：`p50/p95/p99/err_rate`，以及 `request_url/method/response_code/response_body`（可记录样例或聚合）。
  * `err_rate` 建议记录为 0–100 的百分比（你已定义为 `decimal(5,2)`）。

> 状态迁移：`LOAD_TEST_BASELINE` → `DONE`

---

## 7. 幂等性、并发与重试

* **接口级**：

  * 若同一 `taskId` 存在 `status` 属于 `[INIT, GENERATING_CASES, ANALYZING_PATTERNS, RECORDING_READY, INJECTING_AND_REPLAYING, RULES_READY, LOAD_TEST_BASELINE]` 的 `executionId`，且 `force=false`，返回 `409 CONFLICT`（`code=EXECUTION_ALREADY_RUNNING`）。
  * `force=true` 时，可新开一个执行（是否允许并行由你控制；一般不建议同一任务并行）。
* **DB级**：

  * `baggage_map` 依赖 `UNIQUE KEY (execution_id, service_name)`，实现“插入或更新”（UPSERT）。
  * 外部调用失败/超时使用**有限重试**（如退避：1s, 2s, 4s；最多3次）。
* **轮询**：

  * 分析任务与拦截器状态轮询均有超时；超时即置 `FAILED` 并写明 `error_code`。

---

## 8. 关键算法细化

### 8.1 代表性路由挑选（按服务）

* 从 `request_patterns` 取 `record_id = task_execution.record_id` 的数据：

  * `SELECT service_name, method, url, COUNT(*) AS freq FROM request_patterns WHERE record_id=? GROUP BY service_name, method, url ORDER BY service_name, freq DESC;`
* 对每个 `service_name` 取 `freq` 最大的一条（或符合“关键路径”规则的一条）。
* 无历史时，回退 `reqDefId` 的模板（需你提供 `reqDefId → {method,path}` 的映射获取函数）。

### 8.2 baggage 生成与编号

* 单故障执行时：仅携带 `baggage: chaos.f1=<service>-<fault>`。

  > **固定使用 `f1`** 可确保所有下游拦截条件一致，避免错配。
* `baggage_map.value` 用于拦截规则是一个**该服务所有故障**的 tokens 列表，顺序固定（例如按 `fault_config.id ASC` 生成）。

---

## 9. 伪代码骨架（可直接让大模型产出具体代码）

> 语言无关，示意结构，便于落地为 Java/Spring、Go、Node 等。

```pseudo
handler POST /api/tasks/{taskId}/execute (body: options) {
  // 0) 基本校验
  task = detection_task.get(taskId)
  if (!task) return 404 NOT_FOUND

  // 1) 并发控制
  running = task_execution.findRunning(taskId)
  if (running && !options.force) return 409 EXECUTION_ALREADY_RUNNING

  // 2) 新建执行
  exec = task_execution.insert({
    task_id: taskId,
    namespace: task.namespace,
    req_def_id: task.reqDefId,
    request_num: task.request_num,
    status: 'GENERATING_CASES'
  })

  asyncExecute(exec.id, options)   // 异步编排
  return 202 { executionId: exec.id, status: 'INIT', message: 'Execution accepted' }
}

function asyncExecute(executionId, options) {
  try {
    // A) 生成用例 + baggage_map
    topo = topology.getServices(...)
    faults = fault_config.listActiveByTask(taskId)
    cases = generateSimplifiedForTask(task, topo, faults, executionId)
    task_execution.update(executionId, { status: 'ANALYZING_PATTERNS' })

    // B) 触发分析 + 轮询
    analyzeResp = proxy.analyze({ reqDefId: task.reqDefId, namespace: task.namespace,
                                  record_id: task.record_id, serviceList: topo.serviceList, ... })
    task_execution.update(executionId, { analyze_task_id: analyzeResp.taskId, record_id: analyzeResp.recordId })
    waitUntil(() => proxy.taskStatus(analyzeResp.taskId) == 'COMPLETED', options.waitAnalyzeTimeoutSec)
    // 超时抛出异常

    // D) 单故障串行执行
    for service in topo.serviceList:
      serviceFaults = faults.filter(f => f.service == service).sort(byStableOrder)
      for f in serviceFaults:
        try {
          injector.inject(service, f.type)           // 若使用baggage触发，可为NO-OP
          replayResp = proxy.replay(task.namespace, service,
                        headers = { 'baggage': `chaos.f1=${service}-${f.type}` },
                        body = { detection_task_id: taskId, namespace: task.namespace, service_name: service })
          db.insertInterceptReplayResults(executionId, taskId, service, f.type, replayResp, addedHeaders)
        } finally {
          injector.revoke(service, f.type)           // 若注入是NO-OP，则可跳过
        }

    // E) 下发拦截规则
    items = buildInterceptorItemsFrom(replay_results of executionId, baggage_map of executionId)
    recordId = `exec_${executionId}`
    proxy.interceptorsUpsert({ namespace: task.namespace, recordId, ttlSec: options.ttlSecForInterceptors, items })
    task_execution.update(executionId, { status: 'RULES_READY', intercept_record_id: recordId })
    waitInterceptorReady(recordId, options.waitInterceptorReadySec)

    // F) 无故障全量压测
    metrics = runBaselineLoad(testPlanFromRequestPatternsOrReqDefId, concurrency=task.request_num)
    db.insertTestResults(executionId, metrics)
    task_execution.update(executionId, { status: 'DONE', finished_at: now() })

  } catch (err) {
    task_execution.update(executionId, {
      status: 'FAILED',
      error_code: err.code || 'UNCAUGHT',
      error_msg: err.message?.slice(0, 2000),
      finished_at: now()
    })
  }
}
```

---

## 10. SQL 与实现要点

### 10.1 写 `baggage_map`（UPSERT 示例）

```sql
INSERT INTO baggage_map (execution_id, service_name, value)
VALUES (?, ?, ?)
ON DUPLICATE KEY UPDATE value = VALUES(value);
```

* `value` 示例（多故障聚合）：
  `chaos.f1=ts-order-service-pod-delay,chaos.f2=ts-order-service-container-delay`

### 9.2 写 `intercept_replay_results`

* 将回放接口**返回的响应头**、**状态码**、**body**入库；`request_headers` 可存自己发起回放时使用的头（含 `baggage`）。
* `request_url` 来自回放返回的 `url`；`request_method` 来自返回的 `method`。

```

> 如果历史数据或迁移复杂，保留现状也能运行，但应用层需把 `executionId` 转为字符串再写入，读取时也做转换。

---

## 10. 对外调用契约（示例 cURL）

### 10.1 触发分析

```bash
curl -s -X POST http://proxy-host/api/request-patterns/analyze \
  -H 'Content-Type: application/json' \
  -d '{
        "reqDefId": 2,
        "namespace": "train-ticket",
        "record_id": 3,
        "serviceList": ["ts-order-service", "..."],
        "durationSec": 600,
        "autoTriggerRequest": true,
        "requestDelaySeconds": 50,
        "requestCount": 1,
        "requestTimeoutSeconds": 120
      }'
```

轮询直到 `status: COMPLETED`。

### 10.2 回放（单故障）

```bash
curl -s -X GET "http://proxy-host/api/request-patterns/replay/train-ticket/ts-order-service" \
  -H "Content-Type: application/json" \
  -H "baggage: chaos.f1=ts-order-service-pod-delay" \
  -d '{
        "detection_task_id": 3,
        "namespace": "train-ticket",
        "service_name": "ts-order-service"
      }'
```

### 10.3 下发拦截器

```bash
curl -s -X POST http://proxy-host/api/interceptors/upsert \
  -H 'Content-Type: application/json' \
  -d '{
        "namespace": "train-ticket",
        "recordId": "exec_123456",
        "ttlSec": 6000,
        "items": [{
          "serviceName": "ts-order-service",
          "method": "POST",
          "path": "/api/v1/orderservice/order",
          "baggageTokens": ["chaos.f1=ts-order-service-pod-delay","chaos.f2=ts-order-service-container-delay"],
          "respStatus": 200,
          "respHeaders": {"content-type": "application/json;charset=UTF-8"},
          "respBody": "{\"status\":1,\"msg\":\"Success\",\"data\":{\"type\":\"条件拦截\"}}"
        }]
      }'
```

---

## 11. 质量与可观测性

* **重试**：外部依赖（Proxy/拦截器/注入器）网络错误与 5xx 使用退避重试；4xx 不重试。
* **超时**：所有HTTP调用设置合适超时（例如 10–15s），并在配置可调。
* **清理**（可选）：执行完成后可根据 `intercept_record_id` 调用清理接口（若平台提供），或等待 TTL 到期自动失效。

---

## 12. 最小实现清单（交付给大模型的“待产出项”）

1. **控制器**：`POST /api/tasks/{taskId}/execute`（返回 `executionId`）。
2. **服务层**：`ExecutionOrchestrator.run(executionId, options)`（含状态流转与异常处理）。
3. **Case生成器**：`generateSimplifiedForTask(task, topo, faults, executionId)`（含 `baggage_map` 写库与路由挑选）。
4. **ProxyClient**（如有）：`analyze()`、`getTaskStatus()`、`replay()`、`interceptorsUpsert()`、`getInterceptorStatus()`。
5. **FaultInjector**（如有）：`inject()`/`revoke()`（若仅靠 `baggage`，此类可为空实现）。
6. **压测执行器**：`runBaselineLoad(plan, concurrency)`（返回各 `test_case_id` 的 `p50/p95/p99/err_rate`）。
7. **DAO/Repo**：对 `task_execution`、`baggage_map`、`intercept_replay_results`、`test_result` 的读写实现（含 UPSERT）。
8. **配置**：Proxy 基础 URL、超时、重试、TTL、最大等待时间等。

---

## 13. 交付校验清单（验收点）

* 能从 `taskId` 一键拉起全流程，并在 `task_execution` 中看到状态按预期迁移至 `DONE`。
* `baggage_map` 每服务仅一行、值包含该服务所有故障的 `chaos.f*`。
* `intercept_replay_results` 有该 `execution_id` 产生的数据行，字段完整。
* 下发的拦截器使用 `recordId = exec_<executionId>`，`GET /api/fixtures/record/{recordId}/status` 返回 `exists=true`。
* `test_result` 记录了无故障全量压测聚合指标（`p50/p95/p99/err_rate`）。
* 出错时 HTTP 统一错误体，`task_execution` 写入 `FAILED` + `error_code/error_msg`。

---

### （可贴给大模型的提示语样例）

> “请基于本文档实现 `POST /api/tasks/{taskId}/execute`，采用上述状态机与阶段流程，严格按给定的数据库结构与外部接口契约完成：用例生成、Proxy 分析与轮询、录制启动、单故障串行回放入库、拦截器下发与就绪校验、以及无故障全量压测入库。需要具备幂等与并发控制、超时与重试、统一错误响应。请输出：控制器/服务层/ProxyClient/DAO 的代码骨架与关键方法实现、SQL 示例（UPSERT）、以及配置项。”

---

以上方案已对**流程细节、输入输出、数据落库、异常与幂等**做了全面约束，**大模型可以据此直接产出可运行代码**。如果你要我把它转成某种具体语言/框架（例如 Spring Boot 的 Controller/Service/Repository 与 FeignClient 代码、或 Go 的 Gin+GORM 版本），我可以在这套规格上直接生成对应实现。
